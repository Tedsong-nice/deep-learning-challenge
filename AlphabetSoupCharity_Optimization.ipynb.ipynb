{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "\n",
        "# Group rare categories for APPLICATION_TYPE\n",
        "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "rare_application_types = application_type_counts[application_type_counts < 100].index\n",
        "application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(rare_application_types, \"Other\")\n",
        "\n",
        "# Group rare categories for CLASSIFICATION\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "rare_classifications = classification_counts[classification_counts < 100].index\n",
        "application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(rare_classifications, \"Other\")\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "application_df = pd.get_dummies(application_df, drop_first=True)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = application_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
        "y = application_df[\"IS_SUCCESSFUL\"]\n",
        "\n",
        "# Split into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TeddySong\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network model\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "nn.add(tf.keras.layers.Dense(units=100, activation=\"relu\", input_dim=X_train.shape[1]))\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation=\"tanh\"))\n",
        "nn.add(tf.keras.layers.Dense(units=25, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7057 - loss: 0.5794 - val_accuracy: 0.7219 - val_loss: 0.5592\n",
            "Epoch 2/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7251 - loss: 0.5533 - val_accuracy: 0.7236 - val_loss: 0.5565\n",
            "Epoch 3/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7290 - loss: 0.5516 - val_accuracy: 0.7204 - val_loss: 0.5654\n",
            "Epoch 4/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 0.7289 - loss: 0.5514 - val_accuracy: 0.7248 - val_loss: 0.5580\n",
            "Epoch 5/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7313 - loss: 0.5507 - val_accuracy: 0.7259 - val_loss: 0.5530\n",
            "Epoch 6/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7265 - loss: 0.5516 - val_accuracy: 0.7296 - val_loss: 0.5566\n",
            "Epoch 7/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7324 - loss: 0.5478 - val_accuracy: 0.7242 - val_loss: 0.5539\n",
            "Epoch 8/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 0.7327 - loss: 0.5459 - val_accuracy: 0.7255 - val_loss: 0.5552\n",
            "Epoch 9/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.7342 - loss: 0.5474 - val_accuracy: 0.7259 - val_loss: 0.5559\n",
            "Epoch 10/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.7336 - loss: 0.5457 - val_accuracy: 0.7271 - val_loss: 0.5521\n",
            "Epoch 11/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 0.7369 - loss: 0.5405 - val_accuracy: 0.7283 - val_loss: 0.5528\n",
            "Epoch 12/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 0.7379 - loss: 0.5388 - val_accuracy: 0.7232 - val_loss: 0.5549\n",
            "Epoch 13/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5372 - val_accuracy: 0.7278 - val_loss: 0.5527\n",
            "Epoch 14/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7376 - loss: 0.5399 - val_accuracy: 0.7265 - val_loss: 0.5526\n",
            "Epoch 15/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7345 - loss: 0.5438 - val_accuracy: 0.7261 - val_loss: 0.5530\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Add early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = nn.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test), callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "215/215 - 0s - 777us/step - accuracy: 0.7271 - loss: 0.5521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.5521393418312073, Accuracy: 0.7271137237548828\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "\n",
        "# Save the optimized model\n",
        "nn.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the optimized model\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input layer and first hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=150, activation=\"relu\", input_dim=X_train.shape[1]))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\"))\n",
        "\n",
        "# Dropout layer\n",
        "nn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation=\"tanh\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7099 - loss: 0.5805 - val_accuracy: 0.7236 - val_loss: 0.5605\n",
            "Epoch 2/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7290 - loss: 0.5532 - val_accuracy: 0.7261 - val_loss: 0.5635\n",
            "Epoch 3/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7323 - loss: 0.5495 - val_accuracy: 0.7245 - val_loss: 0.5548\n",
            "Epoch 4/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7272 - loss: 0.5547 - val_accuracy: 0.7206 - val_loss: 0.5564\n",
            "Epoch 5/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7292 - loss: 0.5530 - val_accuracy: 0.7300 - val_loss: 0.5569\n",
            "Epoch 6/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7317 - loss: 0.5517 - val_accuracy: 0.7302 - val_loss: 0.5568\n",
            "Epoch 7/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7302 - loss: 0.5480 - val_accuracy: 0.7270 - val_loss: 0.5569\n",
            "Epoch 8/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7315 - loss: 0.5453 - val_accuracy: 0.7290 - val_loss: 0.5542\n",
            "Epoch 9/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7350 - loss: 0.5433 - val_accuracy: 0.7254 - val_loss: 0.5541\n",
            "Epoch 10/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7313 - loss: 0.5460 - val_accuracy: 0.7281 - val_loss: 0.5541\n",
            "Epoch 11/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7324 - loss: 0.5454 - val_accuracy: 0.7284 - val_loss: 0.5537\n",
            "Epoch 12/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7324 - loss: 0.5499 - val_accuracy: 0.7274 - val_loss: 0.5552\n",
            "Epoch 13/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7328 - loss: 0.5419 - val_accuracy: 0.7284 - val_loss: 0.5577\n",
            "Epoch 14/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7341 - loss: 0.5408 - val_accuracy: 0.7283 - val_loss: 0.5533\n",
            "Epoch 15/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7344 - loss: 0.5444 - val_accuracy: 0.7270 - val_loss: 0.5535\n",
            "Epoch 16/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7336 - loss: 0.5440 - val_accuracy: 0.7271 - val_loss: 0.5575\n",
            "Epoch 17/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7313 - loss: 0.5445 - val_accuracy: 0.7248 - val_loss: 0.5541\n",
            "Epoch 18/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7334 - loss: 0.5417 - val_accuracy: 0.7305 - val_loss: 0.5549\n",
            "Epoch 19/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7348 - loss: 0.5400 - val_accuracy: 0.7308 - val_loss: 0.5551\n",
            "Epoch 20/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.5418 - val_accuracy: 0.7216 - val_loss: 0.5597\n",
            "Epoch 21/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7347 - loss: 0.5432 - val_accuracy: 0.7292 - val_loss: 0.5567\n",
            "Epoch 22/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7330 - loss: 0.5390 - val_accuracy: 0.7265 - val_loss: 0.5573\n",
            "Epoch 23/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5365 - val_accuracy: 0.7297 - val_loss: 0.5558\n",
            "Epoch 24/100\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7352 - loss: 0.5407 - val_accuracy: 0.7303 - val_loss: 0.5554\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Add early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = nn.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=100, batch_size=16,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "215/215 - 0s - 782us/step - accuracy: 0.7283 - loss: 0.5533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.5532643795013428, Accuracy: 0.7282798886299133\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "\n",
        "# Save the model\n",
        "nn.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7094 - loss: 0.5844 - val_accuracy: 0.7286 - val_loss: 0.5620\n",
            "Epoch 2/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7279 - loss: 0.5585 - val_accuracy: 0.7232 - val_loss: 0.5595\n",
            "Epoch 3/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7291 - loss: 0.5520 - val_accuracy: 0.7270 - val_loss: 0.5544\n",
            "Epoch 4/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7331 - loss: 0.5488 - val_accuracy: 0.7267 - val_loss: 0.5530\n",
            "Epoch 5/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7290 - loss: 0.5498 - val_accuracy: 0.7308 - val_loss: 0.5531\n",
            "Epoch 6/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7297 - loss: 0.5508 - val_accuracy: 0.7265 - val_loss: 0.5547\n",
            "Epoch 7/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7355 - loss: 0.5425 - val_accuracy: 0.7294 - val_loss: 0.5526\n",
            "Epoch 8/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7321 - loss: 0.5445 - val_accuracy: 0.7264 - val_loss: 0.5545\n",
            "Epoch 9/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7319 - loss: 0.5492 - val_accuracy: 0.7283 - val_loss: 0.5540\n",
            "Epoch 10/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7340 - loss: 0.5443 - val_accuracy: 0.7299 - val_loss: 0.5527\n",
            "Epoch 11/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7356 - loss: 0.5431 - val_accuracy: 0.7284 - val_loss: 0.5546\n",
            "Epoch 12/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5423 - val_accuracy: 0.7281 - val_loss: 0.5542\n",
            "215/215 - 0s - 744us/step - accuracy: 0.7294 - loss: 0.5526\n",
            "Loss: 0.5525943040847778, Accuracy: 0.7294460535049438\n"
          ]
        }
      ],
      "source": [
        "# Define the optimized neural network model\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input layer and first hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=150, activation=\"relu\", input_dim=X_train.shape[1]))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation=\"tanh\"))\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "nn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Add early stopping to prevent overtraining\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = nn.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=100, batch_size=32,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "\n",
        "# Save the optimized model\n",
        "nn.save(\"AlphabetSoupCharity_Optimization.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
